{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "730fd591",
      "metadata": {
        "id": "730fd591"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a2_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d32f8d18",
      "metadata": {
        "id": "d32f8d18"
      },
      "source": [
        "# Group Number:\n",
        "\n",
        "# Student 1:\n",
        "\n",
        "# Student 2:\n",
        "\n",
        "# Student 3:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faec2056",
      "metadata": {
        "id": "faec2056"
      },
      "source": [
        "# Downloading Data and Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7d0580a5",
      "metadata": {
        "id": "7d0580a5"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import requests\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b0756591",
      "metadata": {
        "id": "b0756591"
      },
      "outputs": [],
      "source": [
        "def load_zip(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    zipf = ZipFile(io.BytesIO(response.content))\n",
        "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
        "\n",
        "def load_array(zipfile, fn):\n",
        "    return np.load(io.BytesIO(zipfile[fn]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bb77a4be",
      "metadata": {
        "id": "bb77a4be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36738088-9028-420b-b19d-66192b3a0cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of the training data:\n",
            "\n",
            "positions: (10000, 4, 2, 5)\n",
            "velocities: (10000, 1, 2, 5)\n",
            "charges: (10000, 5, 1)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell loads the training, validation or test data as numpy arrays,\n",
        "with the positions, initial velocities and charge data of the particles.\n",
        "\n",
        "The position arrays are shaped as\n",
        "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
        "\n",
        "The initial velocity arrays are shaped as\n",
        "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
        "\n",
        "The charge arrays are shaped as [simulation id, particle id, 1]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
        "\n",
        "features = ['positions', 'velocities', 'charges']\n",
        "    \n",
        "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
        "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
        "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
        "\n",
        "print('Shapes of the training data:\\n')\n",
        "print(f'positions: {positions_train.shape}')\n",
        "print(f'velocities: {velocities_train.shape}')\n",
        "print(f'charges: {charges_train.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1c3ea4cb",
      "metadata": {
        "id": "1c3ea4cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8613dbc-8acb-4b06-f775-e86321ce4bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An example of retrieving data from the arrays:\n",
            "\n",
            "\n",
            "In simulation 42 of the training set, particle 3 with charge -1.0 had coordinates [ 2.05159559 -1.46130851].\n",
            "The initial velocity of this particle was [ 0.28402364 -0.24784824].\n"
          ]
        }
      ],
      "source": [
        "print('An example of retrieving data from the arrays:\\n\\n')\n",
        "\n",
        "sim_idx = 42\n",
        "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
        "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
        "particle_idx = 3  # corresponds to particle with index 3\n",
        "\n",
        "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
        "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
        "c = charges_train[sim_idx, particle_idx, 0] \n",
        "\n",
        "print(\n",
        "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "10a3438a",
      "metadata": {
        "id": "10a3438a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "371579f3-daaf-48ed-b69c-cc2020363bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overview of no. datapoints:\n",
            "\n",
            "10000 train, 2000 validation, 2000 test simulations\n"
          ]
        }
      ],
      "source": [
        "print('Overview of no. datapoints:\\n')\n",
        "\n",
        "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f9106543",
      "metadata": {
        "id": "f9106543"
      },
      "outputs": [],
      "source": [
        "def plot_example(pos, vel):\n",
        "\n",
        "    fig = plt.figure()\n",
        "    axes = plt.gca()\n",
        "    axes.set_xlim([-5., 5.])\n",
        "    axes.set_ylim([-5., 5.])\n",
        "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
        "    for i in range(pos.shape[-1]):\n",
        "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
        "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
        "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
        "    fig.set_size_inches(7, 7)\n",
        "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
        "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
        "    plt.plot([], [], 'd', color='black', label='initial position')\n",
        "    plt.plot([], [], 'x', color='black', label='final position')\n",
        "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d28681a6",
      "metadata": {
        "id": "d28681a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "9d64711a-c361-401f-dd49-07bc2e0bd476"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "random_idx = np.random.randint(0, 10000)\n",
        "plot_example(positions_train[random_idx], velocities_train[random_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "059b633c",
      "metadata": {
        "id": "059b633c"
      },
      "source": [
        "# Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e6ecb529",
      "metadata": {
        "id": "e6ecb529"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f8633eb8",
      "metadata": {
        "id": "f8633eb8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def dataform_transformation(timepoint, positions, velocities, charges):\n",
        "    \"\"\"\n",
        "    Transform the original set of 6 images to the set of 3 images, \n",
        "    (anchor, support image has same character, support image has different character)\n",
        "\n",
        "    timepoint\n",
        "    \"\"\"\n",
        "    positions_start = positions[:, 0, :, :]\n",
        "    velocities_start = velocities[:, 0, :, :]\n",
        "    charges_start = charges[:, :, :]\n",
        "\n",
        "    temp = np.concatenate((positions_start, velocities_start), axis=1)\n",
        "    temp = np.moveaxis(temp, 1, 2)\n",
        "    input_data = np.concatenate((temp,charges_start), axis=2)\n",
        "\n",
        "    positions_end = positions[:, timepoint, :, :]\n",
        "    label_data = np.moveaxis(positions_end, 1, 2)\n",
        "\n",
        "    return input_data, label_data\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, input_data, label_data):\n",
        "        self.data = torch.FloatTensor(data)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        input = self.input_data[index, :, :]\n",
        "        label = self.label_data[index, :, :]\n",
        "        return input, label\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0a99a32b",
      "metadata": {
        "id": "0a99a32b"
      },
      "outputs": [],
      "source": [
        "train_x,train_label=dataform_transformation(1, positions_train, velocities_train, charges_train)  # time 0.5 1 1.5 correspond to index 1 2 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x.shape)\n",
        "print(train_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jzvMcr0U6yI",
        "outputId": "f83d6b75-c3da-4ae9-fa6e-00cc5e704375"
      },
      "id": "7jzvMcr0U6yI",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 5, 5)\n",
            "(10000, 5, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source= []\n",
        "target = []\n",
        "for i in range(5):\n",
        "  for j in range(5):\n",
        "    if i!=j:\n",
        "      source.append(i)\n",
        "      target.append(j)"
      ],
      "metadata": {
        "id": "uDDdmhtKLOTu"
      },
      "id": "uDDdmhtKLOTu",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install torch_sparse\n",
        "!pip install torch_scatter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3fFroKKNho5",
        "outputId": "0fd4539a-b92e-425c-9e5a-02d48c759aac"
      },
      "id": "f3fFroKKNho5",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch_geometric) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=6b41b110bae5c564628a267876cfe8cb45d991ce94ef31975b8b75b2343a7e56\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_sparse\n",
            "  Downloading torch_sparse-0.6.13.tar.gz (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch_sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl size=501789 sha256=ff539513adcade769c88ffa6cca56f9d75bbe34534849b5cea04a2d2d8d48a10\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/01/be/6b2966e0ff20bb023ae35e5d17903e6e5b4df46dd5892f6be6\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_scatter\n",
            "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=279639 sha256=32b194464db532a66d583dcaf2e3e4869c5081ac01821293db081669f9760c0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp7NZ9WaRu8y",
        "outputId": "6542a44b-b598-4d36-eff5-efa8c892bea7"
      },
      "id": "Bp7NZ9WaRu8y",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPjgsZo8RyDt",
        "outputId": "7534d55a-1959-4b73-d124-0ab7f291aa0c"
      },
      "id": "kPjgsZo8RyDt",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 0, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 4, 0, 1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric import utils\n",
        "\n",
        "# for each small network of particles, edge index is the same\n",
        "edge_index = torch.tensor([source, target], dtype=torch.long)\n",
        "edge_index = utils.sort_edge_index(edge_index)  # and sort them\n",
        "# edge_index, edge_index.shape"
      ],
      "metadata": {
        "id": "5xsm5prcNYEU"
      },
      "id": "5xsm5prcNYEU",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "18b2874d",
      "metadata": {
        "id": "18b2874d"
      },
      "source": [
        "# Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "07e03ddf",
      "metadata": {
        "id": "07e03ddf"
      },
      "outputs": [],
      "source": [
        "num_features = 5\n",
        "num_output = 10\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node_to_emb(nn.Module):  # transforms input nodes to an embedding (similar to word embedding in NLP)\n",
        "    #### why would an embedding layer be useful?\n",
        "\n",
        "    def __init__(self, node_feat_dim=5, node_emb_dim=5):\n",
        "        super().__init__()\n",
        "        self.emb_dim = node_emb_dim\n",
        "        self.node_dim = node_feat_dim\n",
        "        self.emb = nn.Linear(self.node_dim, self.emb_dim)\n",
        "        \n",
        "\n",
        "    def forward(self, nodes):\n",
        "        assert nodes.size(-1) == self.node_dim, 'wrong input dimension of node features!'\n",
        "        out = self.emb(nodes)\n",
        "        return out"
      ],
      "metadata": {
        "id": "vEnjthcxrYFP"
      },
      "id": "vEnjthcxrYFP",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MpLayer(torch.nn.Module):  # a neural message passing layer\n",
        "    def __init__(self, hidden_dim, activation=nn.ReLU()):\n",
        "        super(MpLayer, self).__init__()\n",
        "        \n",
        "        # Hint: which neural networks are used in neural message passing?\n",
        "        self.edge_network = nn.Sequential(nn.Linear(2*hidden_dim, hidden_dim),\n",
        "                                          activation,\n",
        "                                          nn.Linear(hidden_dim, hidden_dim),\n",
        "                                          activation\n",
        "                                          )\n",
        "        \n",
        "        self.node_network = nn.Sequential(nn.Linear(2*hidden_dim, hidden_dim),\n",
        "                                          activation,\n",
        "                                          nn.Linear(hidden_dim, hidden_dim),\n",
        "                                          )\n",
        "        # self.edge_network = nn.Sequential(nn.Linear(120, node_feat_dim),activation)\n",
        "        # self.node_network = nn.Sequential(nn.Linear(node_feat_dim, node_feat_dim),activation)\n",
        "\n",
        "        \n",
        "    def forward(self, input_to_layer):\n",
        "        node_tensor, edge_idx_tensor = input_to_layer\n",
        "        edge_messages_input = torch.concat([node_tensor[edge_idx_tensor[0,:]], node_tensor[edge_idx_tensor[1,:]]], dim=-1) # shape (num_edges, 2*node_dim + edge_dim)\n",
        "        edge_messages_output = self.edge_network(edge_messages_input) # shape (num_edges, hidden_dim)\n",
        "        \n",
        "        #now aggregate the edge messages for each node the edge points to:\n",
        "        \n",
        "        node_agg_messages = torch.zeros(node_tensor.size(0), node_tensor.size(1)).to(node_tensor.device)\n",
        "        node_agg_messages = node_agg_messages.scatter_add_(\n",
        "            dim=0, index=edge_idx_tensor[1].unsqueeze(-1).expand(-1, node_tensor.size(1)), src=edge_messages_output\n",
        "        )\n",
        "        \n",
        "        #### why does the aggregation function need to be permutationally invariant? What is another aggregation function\n",
        "        #### that could be used?\n",
        "        \n",
        "        #put the aggregated messages through the node update network:\n",
        "        node_out = self.node_network(torch.cat([node_tensor, node_agg_messages], dim=-1))\n",
        "\n",
        "        return node_out, edge_idx_tensor"
      ],
      "metadata": {
        "id": "GOFqSe4jzWWd"
      },
      "id": "GOFqSe4jzWWd",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MpGNN(torch.nn.Module): # a message passing GNN\n",
        "    def __init__(self, node_feat_dim, hidden_dim, activation=nn.ReLU(), num_layers=1, num_output=10): # set num_layers=1 because the graph is fully connected \n",
        "    # hidden_dim\n",
        "        super(MpGNN, self).__init__()\n",
        "        \n",
        "        # self.node_to_emb = Node_to_emb(node_feat_dim, hidden_dim)\n",
        "        self.node_to_emb = Node_to_emb(node_feat_dim, hidden_dim)\n",
        "        \n",
        "        self.forward_net = nn.Sequential(\n",
        "            *[MpLayer(hidden_dim, activation) for i in range(num_layers)]\n",
        "        )\n",
        "        self.to_pred = nn.Sequential(nn.Linear(25, 10), torch.nn.ReLU())\n",
        "\n",
        "    def forward(self, x, edge_index, batch=1): # TODO：batch?\n",
        "        input_model = (x, edge_index)\n",
        "        output_model = self.forward_net(input_model)\n",
        "        x,_ = output_model\n",
        "        # x is a 5*5 embedding\n",
        "        \n",
        "        x_flatten = torch.flatten(x)\n",
        "        position_list=self.to_pred(x_flatten)\n",
        "\n",
        "        # out = torch.zeros(max(batch)+1, x.size(1)).to(x.device)\n",
        "        # idx_aggregate_graph = batch.unsqueeze(-1).expand(-1, x.size(1))\n",
        "        # out.scatter_add_(dim=0, index=idx_aggregate_graph, src=x) # aggregate all node embeddings per graph in the batch\n",
        "        # x = self.to_pred(out)\n",
        "        # return x\n",
        "\n",
        "        # out = torch.mean(x, 0, True)[0]\n",
        "        # position_list=[]\n",
        "        # position_list = self.to_pred(out)\n",
        "        # print(position_list.shape)\n",
        "\n",
        "        return position_list"
      ],
      "metadata": {
        "id": "7NN70XfqztEJ"
      },
      "id": "7NN70XfqztEJ",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(4, 4)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2_pGa6RgZ6W",
        "outputId": "2a44a1f3-1b97-4ec1-d428-5e19fca4ab89"
      },
      "id": "K2_pGa6RgZ6W",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1584,  0.3985,  0.4224, -0.4894],\n",
              "        [-0.7430, -0.2869,  1.4805,  1.1265],\n",
              "        [ 0.7137,  0.3768,  0.1512,  1.3289],\n",
              "        [ 0.9053, -0.9378, -0.2163,  0.6780]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(a, 0, True)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twW1WimOgdJN",
        "outputId": "a0c03554-2f87-4d86-8feb-52ec53546e55"
      },
      "id": "twW1WimOgdJN",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2586, -0.1124,  0.4594,  0.6610])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Hint: you might want to try running on the cpu first for easier debugging. \n",
        "Additionally, depending on your implementation, the GPU may not even be faster than the CPU.\n",
        "(note that the focus of this assignment is not the efficiency of the implementation on the GPU).\n",
        "'''\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device='cpu'\n",
        "print(f'Loaded device: {device}')"
      ],
      "metadata": {
        "id": "t7ZeP6e41KeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc58c3b-a809-4e68-d14f-5f1ac757be6c"
      },
      "id": "t7ZeP6e41KeH",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dea70d73",
      "metadata": {
        "id": "dea70d73"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## LOSS Definition ##\n",
        "class loss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Triplets loss variation\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(loss, self).__init__()\n",
        "\n",
        "    def forward(self, prediction, label):\n",
        "      error = prediction - label\n",
        "      squared_error = np.square(error)\n",
        "      losses = np.sum(squared_error)\n",
        "      mean_loss = losses.mean()\n",
        "      return torch.tensor(mean_loss, requires_grad=True)"
      ],
      "metadata": {
        "id": "68TegCXBRPD6"
      },
      "id": "68TegCXBRPD6",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf5fa1b4",
      "metadata": {
        "id": "bf5fa1b4"
      },
      "outputs": [],
      "source": [
        "#todo\n",
        "'''\n",
        "Training the GNN\n",
        "'''\n",
        "model = MpGNN(node_feat_dim=5, hidden_dim=5, num_layers=1,num_output=num_output) # initialize our GNN\n",
        "# print(model)\n",
        "model.to(device)  # and move to the GPU, if possible\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())  # adam usually works well\n",
        "loss_func = loss()  # TODO:换成回归问题对应的loss\n",
        "\n",
        "def train():\n",
        "    model.train()  # set the model to training mode\n",
        "    for i,data in enumerate(train_x):  # loop through the training set in a batch-wise fashion\n",
        "      data = torch.FloatTensor(data)\n",
        "      data.to(device)  # move the batch to the device (GPU if applicable)\n",
        "      optimizer.zero_grad()  # set gradients to 0\n",
        "      out = model(data, edge_index, batch = 1)  # propagate the data through the model\n",
        "      \n",
        "      # TODO: change y_expanded\n",
        "      # y_expanded = torch.zeros(data.y.size(0), 2).to(device)\n",
        "      # y_expanded[:, 0] += data.y == 0\n",
        "      # y_expanded[:, 1] += data.y == 1\n",
        "      y_label = np.array(train_label[i])\n",
        "      out_arr=out.detach().numpy()\n",
        "      # print(out[:1,:], y_expanded[:1,:])\n",
        "      loss = loss_func(out_arr, y_label.ravel())  # two 1d numpy array as input, compute the loss\n",
        "      # if i%100==0:\n",
        "      #   print(loss) # loss没有提升\n",
        "      loss.backward()  # derive gradients\n",
        "      optimizer.step()  # update all parameters based on the gradients"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_label=torch.as_tensor(train_label[i])\n",
        "#       label_flatten=torch.flatten(y_label)\n",
        "#       print(y_label)\n",
        "# #         print(out[:1,:], y_expanded[:1,:])\n",
        "#       # loss = loss_func(out_arr, y_label.ravel())  # two 1d numpy array as input, compute the loss\n",
        "#       loss = nn.MSELoss()\n",
        "#       output = loss(out, label_flatten)"
      ],
      "metadata": {
        "id": "Gz7z_h3A5zZy"
      },
      "id": "Gz7z_h3A5zZy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e2YQIm2vYHD",
        "outputId": "5479ceff-3fd8-4730-e5a0-2f70161c8ca3"
      },
      "id": "6e2YQIm2vYHD",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.93607327, -0.22758755, -0.78778453,  0.02674466, -1.        ],\n",
              "       [ 3.6532299 , -2.7630953 ,  1.58921212, -0.42110171,  1.        ],\n",
              "       [-4.54960211,  8.29976983, -1.29057947,  2.38337883,  1.        ],\n",
              "       [-3.09579099, -3.09210686, -1.91732882, -0.57854192,  1.        ],\n",
              "       [ 0.10730059, -2.89758095,  0.6538811 , -0.56755001, -1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5fb3b29",
      "metadata": {
        "id": "d5fb3b29"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def test(mode=\"train\",time=1):\n",
        "    # index for time should be equal to 1,2 or 3\n",
        "    # todo: maybe remove this line\n",
        "    model.eval()  # set the model to evaluation mode (no dropout)\n",
        "\n",
        "    # todo: if have more time, optimize this because this is redundant\n",
        "    if mode==\"train\":\n",
        "      data_x,data_label=dataform_transformation(time, positions_train, velocities_train, charges_train)\n",
        "    elif mode == \"valid\":\n",
        "      data_x,data_label=dataform_transformation(time, positions_valid, velocities_valid, charges_valid)\n",
        "    else:\n",
        "      data_x,data_label=dataform_transformation(time, positions_test, velocities_test, charges_test)\n",
        "\n",
        "    for i,data in enumerate(data_x):  # loop through the supplied dataset in a batch-wise fashion\n",
        "      data = torch.FloatTensor(data)\n",
        "      data.to(device)  # transfer batch to device\n",
        "      out = model(data, edge_index, batch=1)  # propagate the data through the model\n",
        "      y_label = np.array(data_label[i]).ravel()\n",
        "      out_arr = out.detach().numpy()\n",
        "      cos_sim = dot(y_label, out_arr)/(norm(y_label)*norm(out_arr))\n",
        "    return cos_sim  # return the average cosine similarity"
      ],
      "metadata": {
        "id": "S8ForB_h3stE"
      },
      "id": "S8ForB_h3stE",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2280031f",
      "metadata": {
        "id": "2280031f"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "epochs = 10\n",
        "start = time.time()\n",
        "for epoch in range(1, epochs):  # train for 100 epochs\n",
        "    train()  # do one training step over the entire dataset\n",
        "    with torch.no_grad():\n",
        "        train_sim = test(\"train\")  # compute the training accuracy\n",
        "        val_sim = test(\"valid\")  # compute the validation accuracy\n",
        "    tic = time.time()\n",
        "    print(f'Epoch: {epoch:03d}, Train Similarity: {train_sim:.4f}, Validation Similarity: {val_sim:.4f}. Training time so far: {tic-start:.1f} s')\n",
        "    train_accs.append(train_sim)  # save accuracies so we can plot them\n",
        "    val_accs.append(train_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a8240f1",
      "metadata": {
        "id": "3a8240f1"
      },
      "outputs": [],
      "source": [
        "test_sim = test(\"test\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "A2-4.2-update-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}